{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/berndheidemann/text_classification_first_trys","metadata":{"execution":{"iopub.status.busy":"2023-02-05T09:41:48.882291Z","iopub.execute_input":"2023-02-05T09:41:48.882710Z","iopub.status.idle":"2023-02-05T09:41:49.839051Z","shell.execute_reply.started":"2023-02-05T09:41:48.882672Z","shell.execute_reply":"2023-02-05T09:41:49.837916Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"fatal: destination path '.' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"!python -m spacy download de","metadata":{"execution":{"iopub.status.busy":"2023-02-05T09:42:42.446219Z","iopub.execute_input":"2023-02-05T09:42:42.446636Z","iopub.status.idle":"2023-02-05T09:43:07.555303Z","shell.execute_reply.started":"2023-02-05T09:42:42.446598Z","shell.execute_reply":"2023-02-05T09:43:07.554103Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\nfull pipeline package name 'de_core_news_sm' instead.\u001b[0m\nCollecting de-core-news-sm==3.3.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.3.0/de_core_news_sm-3.3.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from de-core-news-sm==3.3.0) (3.3.2)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.8)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.1.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (4.64.0)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.4.5)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.21.6)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.7.9)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.12)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.4.2)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (8.0.17)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.8.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (6.3.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (23.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (59.8.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.7)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.10.1)\nRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (4.1.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.3.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.8)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.28.1)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.4)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.10.1)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.8.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.26.14)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.1.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (6.0.0)\nInstalling collected packages: de-core-news-sm\nSuccessfully installed de-core-news-sm-3.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndf=pd.read_csv(\"/kaggle/working/text_classification_first_trys/amazon_review_analysis/Amazon-Deutsch-Dataset.csv\")\ndf = df[[\"content\", \"rating\"]]\ndf.rating= df.rating.str[0]\ndf = df.dropna()\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\ntokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n\n# create iterator from tokenized df\ndef df_iterator_content(df):\n    for _, row in df.iterrows():\n        yield tokenizer(row['content'])\n\nvocab = build_vocab_from_iterator(df_iterator_content(df), specials=[\"<unk>\"], min_freq=10)\nvocab.set_default_index(vocab[\"<unk>\"])\nvocab_size = len(vocab)\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-02-05T09:43:07.557615Z","iopub.execute_input":"2023-02-05T09:43:07.558295Z","iopub.status.idle":"2023-02-05T09:43:15.333551Z","shell.execute_reply.started":"2023-02-05T09:43:07.558251Z","shell.execute_reply":"2023-02-05T09:43:15.332341Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"2399\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass AmazonDataset(Dataset):\n    def __init__(self, df, word_count=500, vocab_size=10000):\n        self.df = df\n        self.word_count = word_count\n        self.vocab_size = vocab_size\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        x= self.df.iloc[idx][\"content\"]\n        y= self.df.iloc[idx][\"rating\"]\n        y = int(y) - 1\n        x = vocab(tokenizer(x))\n        if len(x) > self.word_count:\n            x=x[:self.word_count]\n        else:\n            x.extend([0]*(self.word_count-len(x)))\n        x = torch.tensor(x)\n        return x.to(device), torch.tensor(y).to(device)\n\namazon_dataset = AmazonDataset(df, word_count=100, vocab_size=vocab_size)\nx,y=amazon_dataset[0]\nprint(x.shape)\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2023-02-05T09:48:15.526895Z","iopub.execute_input":"2023-02-05T09:48:15.527631Z","iopub.status.idle":"2023-02-05T09:48:23.588412Z","shell.execute_reply.started":"2023-02-05T09:48:15.527595Z","shell.execute_reply":"2023-02-05T09:48:23.587363Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"torch.Size([100])\ntensor(4, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\n\ntorch.manual_seed(1)\n\nclass MyLSTM(nn.Module):\n\n    def __init__(self, embedding_dim, hidden_dim, vocab_size, out_size, word_count=50, dropout=0.2):\n        super(MyLSTM, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.embedding_dim=embedding_dim\n        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n\n        # The LSTM takes word embeddings as inputs, and outputs hidden states\n        # with dimensionality hidden_dim.\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout, num_layers=2)\n        self.dropout=nn.Dropout(p=dropout)\n        # The linear layer that maps from hidden state space to output space\n        self.hidden2output = nn.Linear(hidden_dim*word_count, out_size)\n\n    def forward(self, xb):\n        #print(\"xb shape\", xb.shape)\n        embeds = self.word_embeddings(xb)\n        #print(\"embeds shape\", embeds.shape)\n        lstm_out, _ = self.lstm(embeds)\n        lstm_out=self.dropout(lstm_out)\n        #print(\"lstm_out shape\", lstm_out.shape)\n        # lstm_out_view = lstm_out[:, -1, :]   # works but looses information\n        lstm_out_view = lstm_out.reshape(xb.shape[0], -1   )\n        #print(\"lstm_out_view shape\", lstm_out_view.shape)\n        hidden_space = self.hidden2output(lstm_out_view)\n        #print(\"hidden_space shape\", hidden_space.shape)\n        output = F.log_softmax(hidden_space, dim=1)\n        #print(\"output shape\", output.shape)\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T09:49:25.973577Z","iopub.execute_input":"2023-02-05T09:49:25.973957Z","iopub.status.idle":"2023-02-05T09:49:25.985143Z","shell.execute_reply.started":"2023-02-05T09:49:25.973923Z","shell.execute_reply":"2023-02-05T09:49:25.983169Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import time\n\ndef evaluate(model, dataloader):\n    model.eval()\n    total_acc, total_count = 0, 0\n    with torch.no_grad():\n        for idx, (text, label) in enumerate(dataloader):\n            predicted_label = model(text)\n            total_acc += (predicted_label.argmax(1) == label).sum().item()\n            total_count += label.size(0)\n    return total_acc/total_count","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter\nembed_dim = 64\nnum_class = 5\nhidden_dim = 128\nword_count = 300\nEPOCHS = 30 # epoch\nLR = 0.01  # learning rate\nscheduler_patience=7\nscheduler_factor=0.2\nweight_decay=1e-3\nBATCH_SIZE = 64 # batch size for training\ndropout=0.5\n\n# check if model works\nmodel= MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout).to(device)\ndataset = AmazonDataset(df, word_count=word_count, vocab_size=vocab_size)\nloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n\nxb, yb = next(iter(loader))\nprint(\"yb\", yb)\nprint(\"xb\", xb.shape)\nmodel(xb)","metadata":{"execution":{"iopub.status.busy":"2023-02-05T10:14:03.483226Z","iopub.execute_input":"2023-02-05T10:14:03.483657Z","iopub.status.idle":"2023-02-05T10:14:03.518584Z","shell.execute_reply.started":"2023-02-05T10:14:03.483622Z","shell.execute_reply":"2023-02-05T10:14:03.517582Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"yb tensor([3, 2, 0, 3, 1], device='cuda:0')\nxb torch.Size([5, 300])\n","output_type":"stream"},{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"tensor([[-1.6392, -1.5679, -1.6077, -1.6192, -1.6146],\n        [-1.6168, -1.6189, -1.5804, -1.5918, -1.6404],\n        [-1.6506, -1.5712, -1.5570, -1.6503, -1.6220],\n        [-1.6114, -1.5798, -1.5906, -1.6988, -1.5718],\n        [-1.6726, -1.5943, -1.5562, -1.6255, -1.6023]], device='cuda:0',\n       grad_fn=<LogSoftmaxBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"# create train and valid dataset\ntrain_dataset, valid_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])\n\n# import torch DataLoader\nfrom torch.utils.data import DataLoader\n\nmodel = MyLSTM(embed_dim, hidden_dim, vocab_size, num_class, word_count=word_count, dropout=dropout).to(device)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n\nloss_func = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=weight_decay)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_step_size, gamma=lr_gamma)   # every 10 epochs, LR is multiplied by 0.7\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=scheduler_factor, patience=scheduler_patience)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T10:14:04.130100Z","iopub.execute_input":"2023-02-05T10:14:04.130565Z","iopub.status.idle":"2023-02-05T10:14:04.172187Z","shell.execute_reply.started":"2023-02-05T10:14:04.130505Z","shell.execute_reply":"2023-02-05T10:14:04.170970Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"total_accu = None\ntrain_accus=[]\nvalid_accus=[]\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n    \n    model.train()\n    total_acc, total_count = 0, 0\n\n    for idx, (text, label) in enumerate(train_dataloader):\n        optimizer.zero_grad()\n        predicted_label = model(text)\n        loss = loss_func(predicted_label, label)\n        loss.backward()\n        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n\n    accu_train = evaluate(model, train_dataloader)\n    accu_valid = evaluate(model, valid_dataloader)\n    train_accus.append(accu_train)\n    valid_accus.append(accu_valid)\n    print('-' * 59)\n    print('| end of epoch {:3d} | time: {:5.2f}s | train accuracy {:8.3f} | valid accuracy {:8.3f} | lr: {:1.5f}'.format(\n                                epoch,\n                                time.time() - epoch_start_time,\n                                accu_train, \n                                accu_valid, \n                              #  scheduler.get_last_lr()[0]))\n                                optimizer.param_groups[0]['lr']))\n\n    scheduler.step(accu_valid) # learning rate scheduler after each epoch\n\nimport matplotlib.pyplot as plt\nplt.plot(train_accus, label='train_accu')\nplt.plot(valid_accus, label='valid_accu')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-05T10:14:04.694973Z","iopub.execute_input":"2023-02-05T10:14:04.695326Z","iopub.status.idle":"2023-02-05T10:15:18.012943Z","shell.execute_reply.started":"2023-02-05T10:14:04.695296Z","shell.execute_reply":"2023-02-05T10:15:18.011351Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"-----------------------------------------------------------\n| end of epoch   1 | time:  5.82s | train accuracy    0.327 | valid accuracy    0.305 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   2 | time:  5.74s | train accuracy    0.413 | valid accuracy    0.386 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   3 | time:  5.59s | train accuracy    0.542 | valid accuracy    0.435 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   4 | time:  5.74s | train accuracy    0.621 | valid accuracy    0.462 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   5 | time:  5.54s | train accuracy    0.603 | valid accuracy    0.449 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   6 | time:  6.05s | train accuracy    0.743 | valid accuracy    0.474 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   7 | time:  5.64s | train accuracy    0.815 | valid accuracy    0.500 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   8 | time:  5.71s | train accuracy    0.850 | valid accuracy    0.468 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch   9 | time:  5.57s | train accuracy    0.820 | valid accuracy    0.444 | lr: 0.01000\n-----------------------------------------------------------\n| end of epoch  10 | time:  5.68s | train accuracy    0.913 | valid accuracy    0.504 | lr: 0.00200\n-----------------------------------------------------------\n| end of epoch  11 | time:  5.57s | train accuracy    0.930 | valid accuracy    0.503 | lr: 0.00200\n-----------------------------------------------------------\n| end of epoch  12 | time:  6.10s | train accuracy    0.939 | valid accuracy    0.493 | lr: 0.00200\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_22/4127849258.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0maccu_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0maccu_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_accus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccu_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_22/3918926162.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_22/3927916034.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#print(\"xb shape\", xb.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(\"embeds shape\", embeds.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2181\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# how much valid accuracy do we get in a new untrained model?\nnew_model = MyLSTM(embed_dim, hidden_dim, vocab_size, num_class)\nevaluate(new_model, valid_dataloader)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T10:07:57.479260Z","iopub.status.idle":"2023-02-05T10:07:57.480357Z","shell.execute_reply.started":"2023-02-05T10:07:57.480092Z","shell.execute_reply":"2023-02-05T10:07:57.480117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}