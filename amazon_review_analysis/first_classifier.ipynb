{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>web-scraper-order</th>\n",
       "      <th>web-scraper-start-url</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>next</th>\n",
       "      <th>next-href</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1582056286-2631</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>MHS</td>\n",
       "      <td>Das Beste iPhone aller Zeiten</td>\n",
       "      <td>5. Januar 2020</td>\n",
       "      <td>Ich bin sehr zufrieden mit dem iPhone 11. Der ...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "      <td>Weiter→</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1582056184-2351</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>besser als beim hersteller</td>\n",
       "      <td>21. September 2019</td>\n",
       "      <td>gestern bestellt, heute geliefert. besser geht...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1582056243-2561</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>Joko Müller</td>\n",
       "      <td>Gutes Handy mit kleinen Schwächen</td>\n",
       "      <td>27. Oktober 2019</td>\n",
       "      <td>Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...</td>\n",
       "      <td>4,0 von 5 Sternen</td>\n",
       "      <td>Weiter→</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1582056201-2410</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>Davorko</td>\n",
       "      <td>Ein sehr edles Stück dieses IPHONE 11</td>\n",
       "      <td>2. Januar 2020</td>\n",
       "      <td>Amazon hat wieder super-schnell geliefert. Dan...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "      <td>Weiter→</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1582056246-2585</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>Chiara Natalia Sozzi</td>\n",
       "      <td>Super</td>\n",
       "      <td>18. Oktober 2019</td>\n",
       "      <td>Viel früher angekommen als angegeben, tolles H...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "      <td>Weiter→</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 web-scraper-order  \\\n",
       "0           0   1582056286-2631   \n",
       "1           1   1582056184-2351   \n",
       "2           2   1582056243-2561   \n",
       "3           3   1582056201-2410   \n",
       "4           4   1582056246-2585   \n",
       "\n",
       "                               web-scraper-start-url                author  \\\n",
       "0  https://www.amazon.de/Apple-iPhone-11-128-GB-S...                   MHS   \n",
       "1  https://www.amazon.de/Apple-iPhone-11-128-GB-S...       Amazon Customer   \n",
       "2  https://www.amazon.de/Apple-iPhone-11-128-GB-S...           Joko Müller   \n",
       "3  https://www.amazon.de/Apple-iPhone-11-128-GB-S...               Davorko   \n",
       "4  https://www.amazon.de/Apple-iPhone-11-128-GB-S...  Chiara Natalia Sozzi   \n",
       "\n",
       "                                   title                date  \\\n",
       "0          Das Beste iPhone aller Zeiten      5. Januar 2020   \n",
       "1             besser als beim hersteller  21. September 2019   \n",
       "2      Gutes Handy mit kleinen Schwächen    27. Oktober 2019   \n",
       "3  Ein sehr edles Stück dieses IPHONE 11      2. Januar 2020   \n",
       "4                                  Super    18. Oktober 2019   \n",
       "\n",
       "                                             content             rating  \\\n",
       "0  Ich bin sehr zufrieden mit dem iPhone 11. Der ...  5,0 von 5 Sternen   \n",
       "1  gestern bestellt, heute geliefert. besser geht...  5,0 von 5 Sternen   \n",
       "2  Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...  4,0 von 5 Sternen   \n",
       "3  Amazon hat wieder super-schnell geliefert. Dan...  5,0 von 5 Sternen   \n",
       "4  Viel früher angekommen als angegeben, tolles H...  5,0 von 5 Sternen   \n",
       "\n",
       "      next                                          next-href  Unnamed: 9  \n",
       "0  Weiter→  https://www.amazon.de/Apple-iPhone-11-128-GB-S...         NaN  \n",
       "1      NaN                                                NaN         NaN  \n",
       "2  Weiter→  https://www.amazon.de/Apple-iPhone-11-128-GB-S...         NaN  \n",
       "3  Weiter→  https://www.amazon.de/Apple-iPhone-11-128-GB-S...         NaN  \n",
       "4  Weiter→  https://www.amazon.de/Apple-iPhone-11-128-GB-S...         NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quelle: https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
    "# pip install torchtext\n",
    "# pip install spacy\n",
    "# python -m spacy download de\n",
    "# pip install torch\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"Amazon-Deutsch-Dataset.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin sehr zufrieden mit dem iPhone 11. Der ...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gestern bestellt, heute geliefert. besser geht...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...</td>\n",
       "      <td>4,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon hat wieder super-schnell geliefert. Dan...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Viel früher angekommen als angegeben, tolles H...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content             rating\n",
       "0  Ich bin sehr zufrieden mit dem iPhone 11. Der ...  5,0 von 5 Sternen\n",
       "1  gestern bestellt, heute geliefert. besser geht...  5,0 von 5 Sternen\n",
       "2  Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...  4,0 von 5 Sternen\n",
       "3  Amazon hat wieder super-schnell geliefert. Dan...  5,0 von 5 Sternen\n",
       "4  Viel früher angekommen als angegeben, tolles H...  5,0 von 5 Sternen"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uns interessiert erstmal nur content und rating als Zahl\n",
    "df = df[[\"content\", \"rating\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin sehr zufrieden mit dem iPhone 11. Der ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gestern bestellt, heute geliefert. besser geht...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon hat wieder super-schnell geliefert. Dan...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Viel früher angekommen als angegeben, tolles H...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content rating\n",
       "0  Ich bin sehr zufrieden mit dem iPhone 11. Der ...      5\n",
       "1  gestern bestellt, heute geliefert. besser geht...      5\n",
       "2  Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...      4\n",
       "3  Amazon hat wieder super-schnell geliefert. Dan...      5\n",
       "4  Viel früher angekommen als angegeben, tolles H...      5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating= df.rating.str[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.rating.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3413 entries, 0 to 3412\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   content  3409 non-null   object\n",
      " 1   rating   3409 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 53.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "\n",
    "# create iterator from tokenized df\n",
    "def df_iterator_content(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield tokenizer(row['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(df_iterator_content(df), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1029, 3019, 0, 806]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['Hallo', 'Welt', 'Foo', 'Iphone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x):                           # die benutzen wir später um Text in Vektoren zu übersetzen\n",
    "    return vocab(tokenizer(x))   \n",
    "    \n",
    "label_pipeline = lambda x: int(x) - 1           # (andere Schreibweise) die ratings liegen als Text vor und gehen von 1 bis 5. Daher -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 1131, 1026, 2, 36, 8268]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('Die letzte Bestellung, war fehlerhaft') # Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 2]),\n",
       " tensor([  28,  212,  472,    6,  122,  656,   18,   18,  778,    0,    6,   61,\n",
       "          145, 2043,    2,   26,  146,  129]),\n",
       " tensor([0, 8]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    '''\n",
    "    Extrahiert aus einer Batch von Text die Labels und die Texte und übersetzt diese in Vektoren(Zahlen-Arrays) mittels text_pipeline und label_pipeline\n",
    "    '''\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_text, _label) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "# check if collate_batch works\n",
    "collate_batch([(\"Das neue IPhone ist wirklich toll!!\", \"5\"), (\"FritzBox 7830 ist schon ganz nett, aber geht besser\", \"3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = df[\"rating\"].nunique()\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "train_dataset=df[['content', 'rating']].values;\n",
    "\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  2.14s | train accuracy    0.505 | valid accuracy    0.491 | lr: 5.00\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.65s | train accuracy    0.540 | valid accuracy    0.520 | lr: 5.00\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.69s | train accuracy    0.591 | valid accuracy    0.526 | lr: 5.00\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.61s | train accuracy    0.620 | valid accuracy    0.520 | lr: 3.50\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.61s | train accuracy    0.632 | valid accuracy    0.526 | lr: 3.50\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.87s | train accuracy    0.623 | valid accuracy    0.532 | lr: 3.50\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.60s | train accuracy    0.661 | valid accuracy    0.550 | lr: 2.45\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  1.59s | train accuracy    0.658 | valid accuracy    0.556 | lr: 2.45\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.71s | train accuracy    0.658 | valid accuracy    0.561 | lr: 2.45\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  1.76s | train accuracy    0.694 | valid accuracy    0.509 | lr: 1.71\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time:  2.25s | train accuracy    0.683 | valid accuracy    0.567 | lr: 1.71\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  12 | time:  1.85s | train accuracy    0.713 | valid accuracy    0.520 | lr: 1.71\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  13 | time:  1.59s | train accuracy    0.709 | valid accuracy    0.526 | lr: 1.20\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  14 | time:  1.68s | train accuracy    0.730 | valid accuracy    0.520 | lr: 1.20\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  15 | time:  1.73s | train accuracy    0.729 | valid accuracy    0.526 | lr: 1.20\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  16 | time:  1.64s | train accuracy    0.731 | valid accuracy    0.532 | lr: 0.84\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  17 | time:  1.65s | train accuracy    0.732 | valid accuracy    0.538 | lr: 0.84\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  18 | time:  1.85s | train accuracy    0.747 | valid accuracy    0.526 | lr: 0.84\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     26\u001b[0m total_acc, total_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfor\u001b[39;00m idx, (label, text, offsets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     29\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m     predicted_label \u001b[39m=\u001b[39m model(text, offsets)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m, in \u001b[0;36mcollate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m (_text, _label) \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m     11\u001b[0m      label_list\u001b[39m.\u001b[39mappend(label_pipeline(_label))\n\u001b[0;32m---> 12\u001b[0m      processed_text \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(text_pipeline(_text), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[1;32m     13\u001b[0m      text_list\u001b[39m.\u001b[39mappend(processed_text)\n\u001b[1;32m     14\u001b[0m      offsets\u001b[39m.\u001b[39mappend(processed_text\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m, in \u001b[0;36mtext_pipeline\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtext_pipeline\u001b[39m(x):                           \u001b[39m# die benutzen wir später um Text in Vektoren zu übersetzen\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mreturn\u001b[39;00m vocab(tokenizer(x))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchtext/data/utils.py:14\u001b[0m, in \u001b[0;36m_spacy_tokenize\u001b[0;34m(x, spacy)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_spacy_tokenize\u001b[39m(x, spacy):\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mreturn\u001b[39;00m [tok\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m tok \u001b[39min\u001b[39;00m spacy\u001b[39m.\u001b[39;49mtokenizer(x)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 30 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,collate_fn=collate_batch)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3.0, gamma=0.7)   # every 3 epochs, LR is multiplied by 0.7\n",
    "total_accu = None\n",
    "\n",
    "train_accus=[]\n",
    "valid_accus=[]\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = loss_func(predicted_label, label)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "    accu_train = evaluate(model, train_dataloader)\n",
    "    accu_valid = evaluate(model, valid_dataloader)\n",
    "    train_accus.append(accu_train)\n",
    "    valid_accus.append(accu_valid)\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | train accuracy {:8.3f} | valid accuracy {:8.3f} | lr: {:1.2f}'.format(\n",
    "                                epoch,\n",
    "                                time.time() - epoch_start_time,\n",
    "                                accu_train, \n",
    "                                accu_valid, \n",
    "                                scheduler.get_last_lr()[0]))\n",
    "\n",
    "    scheduler.step() # learning rate scheduler after each epoch\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_accus, label='train_accu')\n",
    "plt.plot(valid_accus, label='valid_accu')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17543859649122806"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how much valid accuracy do we get in a new untrained model?\n",
    "new_model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
    "evaluate(new_model, valid_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
