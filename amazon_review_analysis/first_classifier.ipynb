{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>web-scraper-order</th>\n",
       "      <th>web-scraper-start-url</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>next</th>\n",
       "      <th>next-href</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1582056286-2631</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>MHS</td>\n",
       "      <td>Das Beste iPhone aller Zeiten</td>\n",
       "      <td>5. Januar 2020</td>\n",
       "      <td>Ich bin sehr zufrieden mit dem iPhone 11. Der ...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "      <td>Weiter→</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1582056184-2351</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>besser als beim hersteller</td>\n",
       "      <td>21. September 2019</td>\n",
       "      <td>gestern bestellt, heute geliefert. besser geht...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1582056243-2561</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>Joko Müller</td>\n",
       "      <td>Gutes Handy mit kleinen Schwächen</td>\n",
       "      <td>27. Oktober 2019</td>\n",
       "      <td>Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...</td>\n",
       "      <td>4,0 von 5 Sternen</td>\n",
       "      <td>Weiter→</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1582056201-2410</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>Davorko</td>\n",
       "      <td>Ein sehr edles Stück dieses IPHONE 11</td>\n",
       "      <td>2. Januar 2020</td>\n",
       "      <td>Amazon hat wieder super-schnell geliefert. Dan...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "      <td>Weiter→</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1582056246-2585</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>Chiara Natalia Sozzi</td>\n",
       "      <td>Super</td>\n",
       "      <td>18. Oktober 2019</td>\n",
       "      <td>Viel früher angekommen als angegeben, tolles H...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "      <td>Weiter→</td>\n",
       "      <td>https://www.amazon.de/Apple-iPhone-11-128-GB-S...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 web-scraper-order  \\\n",
       "0           0   1582056286-2631   \n",
       "1           1   1582056184-2351   \n",
       "2           2   1582056243-2561   \n",
       "3           3   1582056201-2410   \n",
       "4           4   1582056246-2585   \n",
       "\n",
       "                               web-scraper-start-url                author  \\\n",
       "0  https://www.amazon.de/Apple-iPhone-11-128-GB-S...                   MHS   \n",
       "1  https://www.amazon.de/Apple-iPhone-11-128-GB-S...       Amazon Customer   \n",
       "2  https://www.amazon.de/Apple-iPhone-11-128-GB-S...           Joko Müller   \n",
       "3  https://www.amazon.de/Apple-iPhone-11-128-GB-S...               Davorko   \n",
       "4  https://www.amazon.de/Apple-iPhone-11-128-GB-S...  Chiara Natalia Sozzi   \n",
       "\n",
       "                                   title                date  \\\n",
       "0          Das Beste iPhone aller Zeiten      5. Januar 2020   \n",
       "1             besser als beim hersteller  21. September 2019   \n",
       "2      Gutes Handy mit kleinen Schwächen    27. Oktober 2019   \n",
       "3  Ein sehr edles Stück dieses IPHONE 11      2. Januar 2020   \n",
       "4                                  Super    18. Oktober 2019   \n",
       "\n",
       "                                             content             rating  \\\n",
       "0  Ich bin sehr zufrieden mit dem iPhone 11. Der ...  5,0 von 5 Sternen   \n",
       "1  gestern bestellt, heute geliefert. besser geht...  5,0 von 5 Sternen   \n",
       "2  Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...  4,0 von 5 Sternen   \n",
       "3  Amazon hat wieder super-schnell geliefert. Dan...  5,0 von 5 Sternen   \n",
       "4  Viel früher angekommen als angegeben, tolles H...  5,0 von 5 Sternen   \n",
       "\n",
       "      next                                          next-href  Unnamed: 9  \n",
       "0  Weiter→  https://www.amazon.de/Apple-iPhone-11-128-GB-S...         NaN  \n",
       "1      NaN                                                NaN         NaN  \n",
       "2  Weiter→  https://www.amazon.de/Apple-iPhone-11-128-GB-S...         NaN  \n",
       "3  Weiter→  https://www.amazon.de/Apple-iPhone-11-128-GB-S...         NaN  \n",
       "4  Weiter→  https://www.amazon.de/Apple-iPhone-11-128-GB-S...         NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quelle: https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
    "# pip install torchtext\n",
    "# pip install spacy\n",
    "# python -m spacy download de\n",
    "# pip install torch\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"Amazon-Deutsch-Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin sehr zufrieden mit dem iPhone 11. Der ...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gestern bestellt, heute geliefert. besser geht...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...</td>\n",
       "      <td>4,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon hat wieder super-schnell geliefert. Dan...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Viel früher angekommen als angegeben, tolles H...</td>\n",
       "      <td>5,0 von 5 Sternen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content             rating\n",
       "0  Ich bin sehr zufrieden mit dem iPhone 11. Der ...  5,0 von 5 Sternen\n",
       "1  gestern bestellt, heute geliefert. besser geht...  5,0 von 5 Sternen\n",
       "2  Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...  4,0 von 5 Sternen\n",
       "3  Amazon hat wieder super-schnell geliefert. Dan...  5,0 von 5 Sternen\n",
       "4  Viel früher angekommen als angegeben, tolles H...  5,0 von 5 Sternen"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uns interessiert erstmal nur content und rating als Zahl\n",
    "df = df[[\"content\", \"rating\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin sehr zufrieden mit dem iPhone 11. Der ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gestern bestellt, heute geliefert. besser geht...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon hat wieder super-schnell geliefert. Dan...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Viel früher angekommen als angegeben, tolles H...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content rating\n",
       "0  Ich bin sehr zufrieden mit dem iPhone 11. Der ...      5\n",
       "1  gestern bestellt, heute geliefert. besser geht...      5\n",
       "2  Ich mach es mal kurz:\\nGut: Optik, Verarbeitun...      4\n",
       "3  Amazon hat wieder super-schnell geliefert. Dan...      5\n",
       "4  Viel früher angekommen als angegeben, tolles H...      5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating= df.rating.str[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3413 entries, 0 to 3412\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   content  3409 non-null   object\n",
      " 1   rating   3409 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 53.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "\n",
    "# create iterator from tokenized df\n",
    "def df_iterator_content(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield tokenizer(row['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(df_iterator_content(df), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1029, 3019, 0, 806]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['Hallo', 'Welt', 'Foo', 'Iphone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x):                           # die benutzen wir später um Text in Vektoren zu übersetzen\n",
    "    return vocab(tokenizer(x))   \n",
    "label_pipeline = lambda x: int(x) - 1           # (andere Schreibweise) die ratings liegen als Text vor und gehen von 1 bis 5. Daher -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 1131, 1026, 36, 8268]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('Die letzte Bestellung war fehlerhaft') # Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_iterator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m _, label \u001b[39min\u001b[39;00m df_iterator(df):\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(label_pipeline(label))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_iterator' is not defined"
     ]
    }
   ],
   "source": [
    "for _, label in df_iterator(df):\n",
    "    print(label_pipeline(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    '''\n",
    "    Extrahiert aus einer Batch von Text die Labels und die Texte und übersetzt diese in Vektoren mittels text_pipeline und label_pipeline\n",
    "    '''\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(df_iterator_content(df), batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_iterator(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield tokenizer(row['content']), row['rating']\n",
    "\n",
    "num_class = len(set([label for (text, label) in df_iterator(df)]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     22\u001b[0m     epoch_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 23\u001b[0m     train(train_dataloader)\n\u001b[1;32m     24\u001b[0m     accu_val \u001b[39m=\u001b[39m evaluate(train_dataloader)\n\u001b[1;32m     25\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m59\u001b[39m)\n",
      "Cell \u001b[0;32mIn[55], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      6\u001b[0m log_interval \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[1;32m      7\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m idx, (label, text, offsets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m     predicted_label \u001b[39m=\u001b[39m model(text, offsets)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[0;32mIn[47], line 8\u001b[0m, in \u001b[0;36mcollate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m label_list, text_list, offsets \u001b[39m=\u001b[39m [], [], [\u001b[39m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m (_label, _text) \u001b[39min\u001b[39;00m batch:\n\u001b[0;32m----> 8\u001b[0m      label_list\u001b[39m.\u001b[39mappend(label_pipeline(_label))\n\u001b[1;32m      9\u001b[0m      processed_text \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(text_pipeline(_text), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[1;32m     10\u001b[0m      text_list\u001b[39m.\u001b[39mappend(processed_text)\n",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtext_pipeline\u001b[39m(x): \n\u001b[1;32m      2\u001b[0m     \u001b[39mreturn\u001b[39;00m vocab(tokenizer(x))   \u001b[39m# die benutzen wir später um Text in Vektoren zu übersetzen\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m label_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39;49m(x) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m           \u001b[39m# die ratings liegen als Text vor und gehen von 1 bis 5. Daher -1\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'list'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. Bitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. Klicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. Weitere Details finden Sie in Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter = df_iterator(df)\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(train_dataloader)\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
